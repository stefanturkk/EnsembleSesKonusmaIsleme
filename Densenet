from google.colab import drive
drive.mount('/content/drive')
##################################################
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.models import Model
from tensorflow.keras.layers import UpSampling2D, Conv2D, concatenate
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def load_images(path, size=(224, 224)):
    images = []
    for img in os.listdir(path):
        img_path = os.path.join(path, img)
        img = load_img(img_path, target_size=size)
        img = img_to_array(img)
        images.append(img)
    return np.array(images)

# Paths to images and masks
images_path = '/content/drive/MyDrive/ayrik1/original_images'
masks_path = '/content/drive/MyDrive/ayrik1/label_images_semantic'

# Load images and masks
images = load_images(images_path)
masks = load_images(masks_path)

# Normalize images
images = images / 255.0

# Convert masks to integer and remove any extra channels
masks = masks.astype(int)
if masks.shape[-1] == 3:  # Assuming masks have 3 channels
    masks = masks[:, :, :, 0]  # Use only the first channel

# Check if masks are correct
print(f"Unique values in masks before one-hot encoding: {np.unique(masks)}")

# One-hot encode the masks
num_classes = np.max(masks) + 1
masks = tf.keras.utils.to_categorical(masks, num_classes=num_classes)

# Ensure masks have the shape (num_samples, 224, 224, num_classes)
print(f"Shape of masks after one-hot encoding: {masks.shape}")

# Display a few images and their corresponding masks
def display_images_and_masks(images, masks, num_images=3):
    plt.figure(figsize=(12, num_images * 4))
    for i in range(num_images):
        plt.subplot(num_images, 2, i * 2 + 1)
        plt.imshow(images[i])
        plt.title("Image")
        plt.axis('off')

        plt.subplot(num_images, 2, i * 2 + 2)
        plt.imshow(np.argmax(masks[i], axis=-1))
        plt.title("Mask")
        plt.axis('off')
    plt.show()

# Display a few examples
display_images_and_masks(images, masks)

# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)



def build_densenet_unet(input_shape, num_classes):
    densenet = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)

    # Encoder
    for layer in densenet.layers:
        layer.trainable = False

    # Decoder
    x = densenet.output

    # Decoder block 1
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(1024, (3, 3), activation='relu', padding='same')(x)
    skip_connection = densenet.get_layer('conv5_block16_concat').output
    skip_connection = UpSampling2D((2, 2))(skip_connection)
    x = concatenate([x, skip_connection])

    # Decoder block 2
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)
    skip_connection = densenet.get_layer('conv4_block24_concat').output
    skip_connection = UpSampling2D((2, 2))(skip_connection)
    x = concatenate([x, skip_connection])

    # Decoder block 3
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    skip_connection = densenet.get_layer('conv3_block12_concat').output
    skip_connection = UpSampling2D((2, 2))(skip_connection)
    x = concatenate([x, skip_connection])

    # Decoder block 4
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    skip_connection = densenet.get_layer('conv2_block6_concat').output
    skip_connection = UpSampling2D((2, 2))(skip_connection)
    x = concatenate([x, skip_connection])

    # Decoder block 5
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    skip_connection = densenet.get_layer('conv1/relu').output
    skip_connection = UpSampling2D((2, 2))(skip_connection)
    x = concatenate([x, skip_connection])

    x = Conv2D(num_classes, (1, 1), activation='softmax')(x)

    return Model(inputs=densenet.input, outputs=x)

input_shape = (224, 224, 3)
model = build_densenet_unet(input_shape, num_classes)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=16)

plot_training_history(history)

# Function to display results
def display_results(image, mask, prediction):
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 3, 1)
    plt.title('Original Image')
    plt.imshow(image)
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.title('Ground Truth')
    plt.imshow(np.argmax(mask, axis=-1))
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.title('Prediction')
    plt.imshow(np.argmax(prediction, axis=-1))
    plt.axis('off')

    plt.show()

# Predict on a validation image
sample_image = X_val[0]
sample_mask = y_val[0]
sample_pred = model.predict(np.expand_dims(sample_image, axis=0))

display_results(sample_image, sample_mask, sample_pred[0])
def plot_training_history(history):
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy')
    plt.legend()

    plt.show()

plot_training_history(history)

# Function to display results
def display_results(image, mask, prediction):
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 3, 1)
    plt.title('Original Image')
    plt.imshow(image)
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.title('Ground Truth')
    plt.imshow(np.argmax(mask, axis=-1))
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.title('Prediction')
    plt.imshow(np.argmax(prediction, axis=-1))
    plt.axis('off')

    plt.show()

# Predict on a validation image
sample_image = X_val[0]
sample_mask = y_val[0]
sample_pred = model.predict(np.expand_dims(sample_image, axis=0))

display_results(sample_image, sample_mask, sample_pred[0])
